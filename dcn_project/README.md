# Data Collection Node (DCN) - Kubernetes Project

## ğŸ“‹ Project Overview

**Data Collection Node (DCN)** is a cloud-native, microservices-based system designed to collect, process, aggregate, and export performance metrics, counters, and telemetry data from various sources. Built on Kubernetes for scalability, reliability, and high availability.

## ğŸ¯ Key Features

### 1. **Multi-Source Data Collection**

- Storage system metrics (ONTAP, StorageGRID, E-Series)
- System performance counters
- Network telemetry data
- Application metrics
- Infrastructure monitoring data

### 2. **Data Processing Pipeline**

- Real-time data ingestion
- Data validation and transformation
- Aggregation and rollup calculations
- Time-series data storage
- Data retention policies

### 3. **Export Capabilities**

- **Prometheus/OpenMetrics** format
- **REST API** endpoints
- **gRPC** streaming
- **Kafka** message bus integration
- **Time-series databases** (InfluxDB, TimescaleDB)

### 4. **Enterprise Features**

- High availability and fault tolerance
- Horizontal auto-scaling
- Multi-tenancy support
- Role-based access control (RBAC)
- TLS/mTLS encryption
- Audit logging
- Health monitoring and alerting

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Data Sources                            â”‚
â”‚  (Storage Systems, APIs, Agents, Network Devices, Applications) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Ingestion Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Collector  â”‚  â”‚   Collector  â”‚  â”‚   Collector  â”‚         â”‚
â”‚  â”‚   Service 1  â”‚  â”‚   Service 2  â”‚  â”‚   Service 3  â”‚  ...    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Message Queue (Kafka)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Processing Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Validator   â”‚â†’ â”‚  Transformer â”‚â†’ â”‚  Aggregator  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Storage Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  TimescaleDB â”‚  â”‚     Redis    â”‚  â”‚   PostgreSQL â”‚         â”‚
â”‚  â”‚  (Time-seriesâ”‚  â”‚    (Cache)   â”‚  â”‚  (Metadata)  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Export Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  REST API    â”‚  â”‚  Prometheus  â”‚  â”‚     gRPC     â”‚         â”‚
â”‚  â”‚   Service    â”‚  â”‚   Exporter   â”‚  â”‚   Service    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Consumers                                 â”‚
â”‚     (Monitoring Tools, Dashboards, Analytics, Alerting)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
dcn_project/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ architecture-diagram.md        # Detailed architecture
â”‚   â”œâ”€â”€ data-flow.md                   # Data flow documentation
â”‚   â””â”€â”€ components.md                  # Component specifications
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ collector/                     # Data collection service
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ collectors/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ontap_collector.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ storagegrid_collector.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ generic_collector.py
â”‚   â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ processor/                     # Data processing service
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ validator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ transformer.py
â”‚   â”‚   â”‚   â””â”€â”€ aggregator.py
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ api/                          # REST API service
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ exporter/                     # Prometheus exporter
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ main.py
â”‚       â”‚   â””â”€â”€ metrics.py
â”‚       â”œâ”€â”€ tests/
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ kubernetes/
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ configmaps/
â”‚   â”‚   â”œâ”€â”€ collector-config.yaml
â”‚   â”‚   â”œâ”€â”€ processor-config.yaml
â”‚   â”‚   â””â”€â”€ api-config.yaml
â”‚   â”œâ”€â”€ secrets/
â”‚   â”‚   â””â”€â”€ dcn-secrets.yaml
â”‚   â”œâ”€â”€ deployments/
â”‚   â”‚   â”œâ”€â”€ collector-deployment.yaml
â”‚   â”‚   â”œâ”€â”€ processor-deployment.yaml
â”‚   â”‚   â”œâ”€â”€ api-deployment.yaml
â”‚   â”‚   â””â”€â”€ exporter-deployment.yaml
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ collector-service.yaml
â”‚   â”‚   â”œâ”€â”€ processor-service.yaml
â”‚   â”‚   â”œâ”€â”€ api-service.yaml
â”‚   â”‚   â””â”€â”€ exporter-service.yaml
â”‚   â”œâ”€â”€ statefulsets/
â”‚   â”‚   â”œâ”€â”€ kafka-statefulset.yaml
â”‚   â”‚   â”œâ”€â”€ timescaledb-statefulset.yaml
â”‚   â”‚   â””â”€â”€ redis-statefulset.yaml
â”‚   â”œâ”€â”€ ingress/
â”‚   â”‚   â””â”€â”€ dcn-ingress.yaml
â”‚   â”œâ”€â”€ hpa/
â”‚   â”‚   â”œâ”€â”€ collector-hpa.yaml
â”‚   â”‚   â”œâ”€â”€ processor-hpa.yaml
â”‚   â”‚   â””â”€â”€ api-hpa.yaml
â”‚   â”œâ”€â”€ rbac/
â”‚   â”‚   â”œâ”€â”€ serviceaccount.yaml
â”‚   â”‚   â”œâ”€â”€ role.yaml
â”‚   â”‚   â””â”€â”€ rolebinding.yaml
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ servicemonitor.yaml
â”‚       â””â”€â”€ prometheusrule.yaml
â”œâ”€â”€ helm/
â”‚   â””â”€â”€ dcn-chart/
â”‚       â”œâ”€â”€ Chart.yaml
â”‚       â”œâ”€â”€ values.yaml
â”‚       â”œâ”€â”€ values-dev.yaml
â”‚       â”œâ”€â”€ values-prod.yaml
â”‚       â””â”€â”€ templates/
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ prometheus-config.yaml
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â””â”€â”€ dashboards/
â”‚   â”‚       â”œâ”€â”€ dcn-overview.json
â”‚   â”‚       â”œâ”€â”€ collector-metrics.json
â”‚   â”‚       â””â”€â”€ performance.json
â”‚   â””â”€â”€ alerts/
â”‚       â””â”€â”€ dcn-alerts.yaml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â”œâ”€â”€ test-deployment.sh
â”‚   â”œâ”€â”€ generate-load.sh
â”‚   â””â”€â”€ backup.sh
â””â”€â”€ docs/
    â”œâ”€â”€ deployment-guide.md
    â”œâ”€â”€ api-documentation.md
    â”œâ”€â”€ metrics-specification.md
    â””â”€â”€ troubleshooting.md
```

## ğŸš€ Quick Start

### Prerequisites

- Kubernetes cluster (v1.28+)
- kubectl configured
- Helm 3.x
- Docker registry access

### 1. Deploy Infrastructure

```bash
# Create namespace
kubectl apply -f kubernetes/namespace.yaml

# Deploy Kafka
kubectl apply -f kubernetes/statefulsets/kafka-statefulset.yaml

# Deploy TimescaleDB
kubectl apply -f kubernetes/statefulsets/timescaledb-statefulset.yaml

# Deploy Redis
kubectl apply -f kubernetes/statefulsets/redis-statefulset.yaml
```

### 2. Deploy DCN Services

```bash
# Apply ConfigMaps and Secrets
kubectl apply -f kubernetes/configmaps/
kubectl apply -f kubernetes/secrets/

# Deploy services
kubectl apply -f kubernetes/deployments/
kubectl apply -f kubernetes/services/

# Deploy Ingress
kubectl apply -f kubernetes/ingress/
```

### 3. Verify Deployment

```bash
# Check all pods are running
kubectl get pods -n dcn

# Check services
kubectl get svc -n dcn

# Test API endpoint
curl http://dcn-api.example.com/health
```

## ğŸ“Š Metrics and Counters

### Counter Categories

#### 1. **Storage Performance Counters**

- IOPS (Read/Write/Total)
- Throughput (MB/s)
- Latency (ms)
- Queue Depth
- Cache Hit Ratio

#### 2. **System Counters**

- CPU Utilization (%)
- Memory Usage (GB)
- Disk I/O
- Network Traffic (packets/bytes)
- Process Statistics

#### 3. **Application Counters**

- Request Rate (req/s)
- Error Rate (%)
- Response Time (ms)
- Active Connections
- Queue Length

#### 4. **Business Metrics**

- Data Ingestion Rate
- Processing Lag
- Export Success Rate
- API Request Count
- Data Retention Status

### Prometheus Metrics Format

```prometheus
# Storage IOPS
dcn_storage_iops_total{cluster="prod-01",node="node-1",type="read"} 1500
dcn_storage_iops_total{cluster="prod-01",node="node-1",type="write"} 800

# Latency
dcn_storage_latency_milliseconds{cluster="prod-01",node="node-1",operation="read"} 2.5

# Throughput
dcn_storage_throughput_bytes_per_second{cluster="prod-01",node="node-1"} 104857600

# Service health
dcn_service_up{service="collector",instance="collector-1"} 1
dcn_service_requests_total{service="api",endpoint="/metrics",status="200"} 45123

# Processing metrics
dcn_data_processing_lag_seconds{pipeline="main"} 1.2
dcn_data_validation_errors_total{type="schema_mismatch"} 5
```

## ğŸ” Security

### Authentication & Authorization

- **JWT tokens** for API access
- **mTLS** for service-to-service communication
- **RBAC** for Kubernetes resources
- **API keys** for external clients

### Data Security

- Encryption at rest (storage volumes)
- Encryption in transit (TLS 1.3)
- Secret management (Kubernetes Secrets/Vault)
- Network policies for traffic control

## ğŸ“ˆ Scalability

### Horizontal Scaling

- Collector services: Scale based on data source count
- Processor services: Scale based on queue depth
- API services: Scale based on request rate
- Auto-scaling with HPA (CPU/Memory/Custom metrics)

### Performance Targets

- **Data Ingestion**: 100K+ metrics/second
- **API Latency**: < 100ms (p95)
- **Data Retention**: 30 days (raw), 1 year (aggregated)
- **Availability**: 99.9% uptime

## ğŸ”§ Configuration

### Environment Variables

```bash
# Collector Service
COLLECTOR_POLL_INTERVAL=60s
COLLECTOR_TIMEOUT=30s
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
LOG_LEVEL=INFO

# Processor Service
KAFKA_CONSUMER_GROUP=dcn-processors
BATCH_SIZE=1000
PROCESSING_THREADS=4

# API Service
API_PORT=8080
DATABASE_URL=postgresql://user:pass@timescaledb:5432/dcn
REDIS_URL=redis://redis:6379
CACHE_TTL=300

# Exporter Service
METRICS_PORT=9090
SCRAPE_INTERVAL=15s
```

## ğŸ§ª Testing

### Unit Tests

```bash
cd services/collector
pytest tests/ --cov=src --cov-report=html
```

### Integration Tests

```bash
./scripts/test-deployment.sh
```

### Load Testing

```bash
./scripts/generate-load.sh --rate 10000 --duration 300s
```

## ğŸ“Š Monitoring & Observability

### Grafana Dashboards

- **DCN Overview**: System-wide metrics and health
- **Collector Metrics**: Data collection statistics
- **Processing Pipeline**: Data flow and lag monitoring
- **API Performance**: Request rates and latencies

### Alerts

- Service down alerts
- High error rate warnings
- Data processing lag alerts
- Storage capacity warnings
- API latency spikes

## ğŸ”„ Backup & Disaster Recovery

### Backup Strategy

- Database backups: Daily full, hourly incremental
- Configuration backups: Version controlled
- Kafka topic retention: 7 days
- Disaster recovery time: < 1 hour RPO

## ğŸ“š API Documentation

### REST API Endpoints

```
GET  /health                     - Health check
GET  /ready                      - Readiness probe
GET  /metrics                    - Prometheus metrics
GET  /api/v1/counters            - List all counter types
GET  /api/v1/counters/{type}     - Get specific counter data
POST /api/v1/query               - Query time-series data
GET  /api/v1/sources             - List data sources
GET  /api/v1/export/{format}     - Export data in format
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

## ğŸ“ License

Copyright Â© 2026 NetApp Inc. All rights reserved.

## ğŸ“ Support

- **Documentation**: `/docs` directory
- **Issues**: Create GitHub issue
- **Email**: dcn-support@netapp.com
- **Slack**: #dcn-support

---

**Version**: 1.0.0  
**Last Updated**: February 2026  
**Maintained By**: HCE Core Engineering Team
